name: "Checks"

env:
  IS_RELEASE_BRANCH: ${{ startsWith(github.head_ref, 'release-please-') }}

on:
  pull_request:
    types:
      - opened
      - synchronize
      - reopened
  push:
    branches:
      - main
  merge_group:
    branches:
      - main
    types:
      - checks_requested
  workflow_call:

permissions: {}

jobs:
  go:
    runs-on: ubuntu-22.04
    permissions:
      checks: write
      contents: read
      pull-requests: write
    strategy:
      matrix:
        directory:
          - examples
          - sdk
          - service
          - lib/ocrypto
          - lib/fixtures
          - lib/flattening
          - lib/identifier
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          fetch-depth: 0
          persist-credentials: false
      - uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b #v5.4.0
        with:
          go-version-file: ${{ matrix.directory }}/go.mod
          check-latest: false
          cache-dependency-path: |
            examples/go.sum
            protocol/go/go.sum
            sdk/go.sum
            service/go.sum
      - if: env.IS_RELEASE_BRANCH == 'true'
        name: prevent depending on unreleased upstream changes
        run: ./.github/scripts/work-init.sh
      - if: github.head_ref == format('release-please--branches--main--components--{0}', matrix.directory)
        name: prevent tagging with replace directives
        run: go mod edit --json | jq -e '.Replace | not'
        working-directory: ${{ matrix.directory }}
      - run: go mod download
        working-directory: ${{ matrix.directory }}
      - run: go mod verify
        working-directory: ${{ matrix.directory }}
      - run: go work use .
        if: env.IS_RELEASE_BRANCH == 'true'
        working-directory: ${{ matrix.directory }}
      - name: govluncheck
        uses: golang/govulncheck-action@b625fbe08f3bccbe446d94fbf87fcc875a4f50ee
        with:
          go-version-input: "1.24.2"
          work-dir: ${{ matrix.directory }}
      - name: golangci-lint
        uses: golangci/golangci-lint-action@4afd733a84b1f43292c63897423277bb7f4313a9 # v8.0.0
        with:
          version: v2.1
          working-directory: ${{ matrix.directory }}
          skip-cache: true
          only-new-issues: true
          # args: --out-format=colored-line-number
      - if: matrix.directory == 'service'
        run: .github/scripts/init-temp-keys.sh
      - run: go test ./... -short
        working-directory: ${{ matrix.directory }}
      - if: matrix.directory == 'service'
        run: go test ./service/integration -race -failfast
      - name: check go fmt and go mod tidy
        run: |-
          go mod tidy
          go fmt ./...
          git restore go.sum
        working-directory: ${{ matrix.directory }}
      - run: git diff
      - run: git diff-files --ignore-submodules
      - name: Check that files have been formatted before PR submission; see above for error details
        run: git diff-files --quiet --ignore-submodules
        if: env.IS_RELEASE_BRANCH == 'false'

  integration:
    permissions:
      contents: read
    name: integration tests
    runs-on: ubuntu-22.04
    env:
      TLS_ENABLED: "true"
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          persist-credentials: false
      - uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b #v5.4.0
        with:
          go-version-file: "service/go.mod"
          check-latest: false
          cache-dependency-path: |
            service/go.sum
            examples/go.sum
            protocol/go/go.sum
            sdk/go.sum
      - if: env.IS_RELEASE_BRANCH == 'true'
        run: ./.github/scripts/work-init.sh
      - run: go mod download
      - run: go mod verify
      - name: Install mkcert
        run: |
          sudo apt-get install -y libnss3-tools
          curl -JLO "https://dl.filippo.io/mkcert/latest?for=linux/amd64"
          chmod +x mkcert-v*-linux-amd64
          sudo cp mkcert-v*-linux-amd64 /usr/local/bin/mkcert
      - run: |
          .github/scripts/init-temp-keys.sh
          mkcert -install
          mkcert -cert-file ./keys/platform.crt -key-file ./keys/platform-key.pem localhost
          cp opentdf-dev.yaml opentdf.yaml
          yq eval '.server.tls.enabled = true' -i opentdf.yaml
      - name: Added Trusted Certs
        run: |
          sudo chmod -R 777 ./keys
          sudo apt-get install -y ca-certificates
          sudo cp ./keys/localhost.crt /usr/local/share/ca-certificates
          sudo update-ca-certificates
      - run: docker compose up -d --wait --wait-timeout 240 || (docker compose logs && exit 1)
      - run: go run ./service provision keycloak
      - run: go run ./service provision fixtures
      - uses: JarvusInnovations/background-action@2428e7b970a846423095c79d43f759abf979a635
        name: start server in background
        with:
          run: >
            go build -o opentdf -v service/main.go
            && .github/scripts/watch.sh opentdf.yaml ./opentdf start
          wait-on: |
            tcp:localhost:8080
          log-output-if: true
          wait-for: 90s
      - run: go install github.com/fullstorydev/grpcurl/cmd/grpcurl@v1.8.9
      - name: Setup Bats and bats libs
        uses: bats-core/bats-action@3.0.0
      - run: test/service-start.bats
      - run: test/tdf-roundtrips.bats
      - run: test/policy-service.bats
      - name: verify bultin casbin policy
        run: test/builtin-casbin.bats
      - name: create roundtrip test data and run tests
        run: go test ./service/rttests -v
      - name: enable static entitlements rego policy
        run: yq eval '.services.authorization.rego.path = "./test/rego/static-entitlements.rego"' -i opentdf.yaml
      - run: sleep 30
      - name: validate static rego policy
        run: test/rego/static-entitlements.bats
      - name: enable custom entity rego policy
        run: yq eval '.services.authorization.rego.path = "./test/rego/custom-entity.rego"' -i opentdf.yaml
      - run: sleep 30
      - name: validate custom entity rego policy
        run: test/rego/custom-entity.bats


  benchmark:
    permissions:
      contents: read
      pull-requests: write # Needed to comment on PRs
    name: benchmark tests
    runs-on: ubuntu-22.04
    env:
      TLS_ENABLED: "true"
      # Define the degradation threshold (5% = 0.05)
      # For time metrics, PR > main * (1 + threshold) is degradation
      # For throughput metrics, PR < main * (1 - threshold) is degradation
      DEGRADATION_THRESHOLD: 0.05
    outputs: # Define job outputs for potential use in later jobs (optional)
      comparison_results: ${{ steps.compare_benchmarks.outputs.comparison_summary }}
      degradation_detected: ${{ steps.check_degradation.outputs.degraded }}
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          persist-credentials: false
          # Fetch main as well for later comparison checkout
          fetch-depth: 0 # Fetch all history for switching branches

      - name: Get PR SHA
        id: pr_sha
        run: echo "sha=$(git rev-parse HEAD)" >> "$GITHUB_OUTPUT"

      - uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b #v5.4.0
        with:
          go-version-file: "service/go.mod"
          check-latest: false
          cache-dependency-path: |
            service/go.sum
            examples/go.sum
            protocol/go/go.sum
            sdk/go.sum
      - if: env.IS_RELEASE_BRANCH == 'true'
        run: ./.github/scripts/work-init.sh
      - run: go mod download
      - run: go mod verify
      - name: Install mkcert
        run: |
          sudo apt-get install -y libnss3-tools
          curl -JLO "https://dl.filippo.io/mkcert/latest?for=linux/amd64"
          chmod +x mkcert-v*-linux-amd64
          sudo cp mkcert-v*-linux-amd64 /usr/local/bin/mkcert
      - run: |
          .github/scripts/init-temp-keys.sh
          mkcert -install
          mkcert -cert-file ./keys/platform.crt -key-file ./keys/platform-key.pem localhost
          cp opentdf-dev.yaml opentdf.yaml
          yq eval '.server.tls.enabled = true' -i opentdf.yaml
          yq eval '.trace = {"enabled":true}' -i opentdf.yaml
      - name: Added Trusted Certs
        run: |
          sudo chmod -R 777 ./keys
          sudo apt-get install -y ca-certificates
          sudo cp ./keys/localhost.crt /usr/local/share/ca-certificates
          sudo update-ca-certificates
      - run: docker compose up -d --wait --wait-timeout 240 || (docker compose logs && exit 1)
      - run: go run ./service provision keycloak
      - run: go run ./service provision fixtures

      # --- Build and Start Server (PR Version) ---
      - name: Build Go Binaries (PR)
        id: build_pr
        run: |
          echo "Building service..."
          go build -o opentdf-pr -v service/main.go
          # Sanitize and validate the output values
          PR_SERVICE_BIN="opentdf-pr" # Fixed value instead of dynamic
          if [[ ! -f "$PR_SERVICE_BIN" ]]; then
          echo "Error: Built binary not found"
          exit 1
          fi
          echo "service_bin=${PR_SERVICE_BIN}" >> $GITHUB_OUTPUT
          # Similar validation for examples binary
          cd examples && go build -o examples-pr . && cd ..
          EXAMPLES_BIN="examples/examples-pr" # Fixed value
          if [[ ! -f "$EXAMPLES_BIN" ]]; then
          echo "Error: Built examples binary not found"
          exit 1
          fi
          echo "examples_bin=${EXAMPLES_BIN}" >> $GITHUB_OUTPUT

      - uses: JarvusInnovations/background-action@2428e7b970a846423095c79d43f759abf979a635
        name: Start Server (PR) in Background
        id: server_pr
        with:
          run: |
            echo "Starting PR server: ${{ steps.build_pr.outputs.service_bin }}"
            .github/scripts/watch.sh opentdf.yaml ./${{ steps.build_pr.outputs.service_bin }} start
          wait-on: tcp:localhost:8080
          log-output-if: true
          log-name: server-pr-log # Unique log name
          wait-for: 120s

      # --- Run Benchmarks (PR Version) ---
      - name: Run PR Benchmarks & Save Output
        id: run_pr_benchmarks
        run: |
          echo "Running PR benchmarks..."
          EXAMPLES_BIN="./${{ steps.build_pr.outputs.examples_bin }}" # Use the built PR examples binary

          # Create directory for results
          mkdir -p benchmark_results/pr

          echo "Running Decision Benchmark (PR)..."
          $EXAMPLES_BIN benchmark-decision --count 1000 > benchmark_results/pr/decision.txt 2>&1 || echo "Decision benchmark (PR) failed, continuing..."
          cat benchmark_results/pr/decision.txt # Log output

          # Add other benchmarks similarly:
          echo "Running Bulk Benchmark (PR)..."
          $EXAMPLES_BIN benchmark-bulk --tdf tdf3 --count 100 > benchmark_results/pr/bulk.txt 2>&1 || echo "Bulk benchmark (PR) failed, continuing..."
          cat benchmark_results/pr/bulk.txt

          echo "Running TDF3 Benchmark (PR)..."
          $EXAMPLES_BIN benchmark --count=1000 --concurrent=10 > benchmark_results/pr/tdf3.txt 2>&1 || echo "TDF3 benchmark (PR) failed, continuing..." # Reduced count for faster CI
          cat benchmark_results/pr/tdf3.txt

          echo "Running NanoTDF Benchmark (PR)..."
          $EXAMPLES_BIN benchmark --storeCollectionHeaders=false --tdf=nanotdf --count=1000 --concurrent=10 > benchmark_results/pr/nano.txt 2>&1 || echo "Nano benchmark (PR) failed, continuing..." # Reduced count
          cat benchmark_results/pr/nano.txt

          echo "Collecting Metrics (PR)..."
          $EXAMPLES_BIN metrics > benchmark_results/pr/metrics.txt 2>&1 || echo "Metrics collection (PR) failed, continuing..."
          cat benchmark_results/pr/metrics.txt

      - name: Stop Server (PR)
        if: always() # Ensure server stops even if benchmarks fail
        run: |
          echo "Stopping PR server process..."
          # Find and kill the specific background process if background-action doesn't handle it well on failure/cancellation
          # This might require more sophisticated process management depending on how background-action works internally.
          # A simpler approach for CI might be to kill all 'opentdf-pr' processes.
          pkill -f "${{ steps.build_pr.outputs.service_bin }}" || echo "PR Server process not found or already stopped."
          sleep 5 # Give time for ports to free up

      - name: Clean Workspace and Checkout Main
        run: |
          echo "Cleaning workspace..."
          # Remove binaries built from PR to avoid confusion
          rm -f ${{ steps.build_pr.outputs.service_bin }} examples/${{ steps.build_pr.outputs.examples_bin }}
          # Add other specific files to clean if necessary
          # git clean -fdx # Use with caution - removes ALL untracked files/dirs

          echo "Checking out main branch..."
          git checkout main
          git pull origin main --ff-only # Ensure it's up-to-date

      - name: Get Main SHA
        id: main_sha
        run: echo "sha=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT

      # --- Rebuild and Start Server (Main Version) ---
      # Dependencies (Docker, Keycloak) should still be running
      - name: Build Go Binaries (Main)
        id: build_main
        run: |
          echo "Building service (main)..."
          go build -o opentdf-main -v service/main.go
          echo "Building examples (main)..."
          cd examples && go build -o examples-main . && cd ..
          echo "::set-output name=service_bin::opentdf-main"
          echo "::set-output name=examples_bin::examples/examples-main"

      - uses: JarvusInnovations/background-action@2428e7b970a846423095c79d43f759abf979a635
        name: Start Server (Main) in Background
        id: server_main
        with:
          run: |
            echo "Starting Main server: ${{ steps.build_main.outputs.service_bin }}"
            # Use the *same* config file (opentdf.yaml)
            .github/scripts/watch.sh opentdf.yaml ./${{ steps.build_main.outputs.service_bin }} start
          wait-on: tcp:localhost:8080
          log-output-if: true
          log-name: server-main-log # Unique log name
          wait-for: 120s

      # --- Run Benchmarks (Main Version) ---
      - name: Run Main Benchmarks & Save Output
        id: run_main_benchmarks
        run: |
          echo "Running Main benchmarks..."
          EXAMPLES_BIN="./${{ steps.build_main.outputs.examples_bin }}" # Use the built Main examples binary

          mkdir -p benchmark_results/main

          echo "Running Decision Benchmark (Main)..."
          $EXAMPLES_BIN benchmark-decision --count 1000 > benchmark_results/main/decision.txt 2>&1 || echo "Decision benchmark (Main) failed, continuing..."
          cat benchmark_results/main/decision.txt

          # Add other benchmarks similarly:
          echo "Running Bulk Benchmark (Main)..."
          $EXAMPLES_BIN benchmark-bulk --tdf tdf3 --count 100 > benchmark_results/main/bulk.txt 2>&1 || echo "Bulk benchmark (Main) failed, continuing..."
          cat benchmark_results/main/bulk.txt

          echo "Running TDF3 Benchmark (Main)..."
          $EXAMPLES_BIN benchmark --count=1000 --concurrent=10 > benchmark_results/main/tdf3.txt 2>&1 || echo "TDF3 benchmark (Main) failed, continuing..."
          cat benchmark_results/main/tdf3.txt

          echo "Running NanoTDF Benchmark (Main)..."
          $EXAMPLES_BIN benchmark --storeCollectionHeaders=false --tdf=nanotdf --count=1000 --concurrent=10 > benchmark_results/main/nano.txt 2>&1 || echo "Nano benchmark (Main) failed, continuing..."
          cat benchmark_results/main/nano.txt

          echo "Collecting Metrics (Main)..."
          $EXAMPLES_BIN metrics > benchmark_results/main/metrics.txt 2>&1 || echo "Metrics collection (Main) failed, continuing..."
          cat benchmark_results/main/metrics.txt

      - name: Stop Server (Main)
        if: always()
        run: |
          echo "Stopping Main server process..."
          pkill -f ${{ steps.build_main.outputs.service_bin }} || echo "Main Server process not found or already stopped."
          sleep 5

      - name: Compare Benchmarks
        id: compare_benchmarks
        run: |
          echo "Comparing benchmark results..."
          # Use a script for cleaner comparison logic
          .github/scripts/compare_benchmarks.sh benchmark_results/pr benchmark_results/main $DEGRADATION_THRESHOLD > benchmark_comparison.md
          echo "Comparison Results:"
          cat benchmark_comparison.md

          # Save comparison summary to output and environment for comment step
          COMPARISON_SUMMARY=$(cat benchmark_comparison.md)
          echo "comparison_summary<<EOF_COMP" >> $GITHUB_OUTPUT
          echo "$COMPARISON_SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF_COMP" >> $GITHUB_OUTPUT

          echo "BENCHMARK_COMPARISON_OUTPUT<<EOF_COMP_ENV" >> $GITHUB_ENV
          echo "$COMPARISON_SUMMARY" >> $GITHUB_ENV
          echo "EOF_COMP_ENV" >> $GITHUB_ENV

          # Also save individual PR results for the comment fallback/fork case
          # (Could parse the PR files here or just use the raw files if needed)
          # For simplicity, we'll just use the comparison summary for now.

      - name: Check for Degradation
        id: check_degradation
        # Use the exit code of the comparison script or parse its output
        run: |
          if ! .github/scripts/compare_benchmarks.sh benchmark_results/pr benchmark_results/main $DEGRADATION_THRESHOLD --check-only; then
            echo "::error::Benchmark degradation detected!"
            echo "degraded=true" >> $GITHUB_OUTPUT
            # Optionally exit 1 here if you want the *step* to fail visibly,
            # but the github-script step below handles the job failure logic.
            # exit 1 # Uncomment to make this step fail
          else
            echo "No significant benchmark degradation detected."
            echo "degraded=false" >> $GITHUB_OUTPUT
          fi

      - name: Save Benchmark Results and Comparison to Comment/Summary
        # This step now uses the comparison output and decides whether to fail
        if: github.event_name == 'pull_request' || github.event_name == 'workflow_call'
        uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea #v7.0.1
        with:
          script: |
            const comparisonOutput = process.env.BENCHMARK_COMPARISON_OUTPUT || '## Benchmark Comparison Failed';
            const prSHA = "${{ steps.pr_sha.outputs.sha }}".substring(0, 7);
            const mainSHA = "${{ steps.main_sha.outputs.sha }}".substring(0, 7);
            const degradationDetected = "${{ steps.check_degradation.outputs.degraded }}" === "true";
            const isFork = "${{ github.event.pull_request.head.repo.fork }}" === "true";
            const eventName = "${{ github.event_name }}";

            let body = `<details><summary>Benchmark Comparison vs main (${mainSHA}), click to expand</summary>\n\n`;
            body += `**PR Commit:** ${prSHA}\n`;
            body += `**Main Commit:** ${mainSHA}\n\n`;
            body += comparisonOutput;
            body += `\n</details>`;

            if (degradationDetected) {
              body += `\n\n**Performance degradation detected!** ðŸ“‰`;
              core.setFailed('Benchmark performance degraded significantly compared to main.'); // Fail the JOB
            } else {
              body += `\n\n**No significant performance degradation detected.** âœ…`;
            }

            // Decide where to put the results
            if (eventName === 'pull_request' && !isFork) {
              // Comment on PR for non-forks
              try {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: body,
                });
                core.info('Posted benchmark comparison comment to PR.');
              } catch (error) {
                core.error(`Failed to comment on PR: ${error}`);
                // Fallback to summary if commenting fails
                core.summary.addRaw(body).write();
              }
            } else {
              // Add to job summary for forks, pushes, workflow_calls, etc.
              core.summary.addRaw(body).write();
              core.info('Added benchmark comparison to job summary.');
            }

      - name: Checkout Back to PR Commit
        if: always() && github.event_name == 'pull_request' # Only relevant for PRs
        run: |
          echo "Checking back out to PR commit: ${{ steps.pr_sha.outputs.sha }}"
          git checkout ${{ steps.pr_sha.outputs.sha }}

      - name: Final Docker Cleanup (Optional)
        if: always()
        run: |
          echo "Stopping and removing docker compose services..."
          docker compose down -v --remove-orphans # Clean up volumes too

  image:
    permissions:
      contents: read
    name: image build
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          persist-credentials: false
      - uses: docker/setup-buildx-action@d70bba72b1f3fd22344832f00baa16ece964efeb
        with:
          cache-binary: false
      - uses: docker/build-push-action@48aba3b46d1b1fec4febb7c5d0c644b249a11355 # v6.10.0
        with:
          context: .
          file: ./Dockerfile
          push: false

  platform-xtest:
    permissions:
      contents: read
      packages: read
    uses: opentdf/tests/.github/workflows/xtest.yml@main
    with:
      focus-sdk: go
      # use commit instead of ref so we can "go get" specific sdk version
      platform-ref: ${{ github.event.pull_request.head.sha || github.sha }} lts

  # test latest otdfctl CLI 'main' against platform PR branch
  otdfctl-test:
    permissions:
      contents: read
    name: otdfctl e2e tests
    runs-on: ubuntu-latest
    steps:
      - uses: opentdf/platform/test/start-up-with-containers@main
        with:
          platform-ref: ${{ github.event.pull_request.head.sha || github.sha }}
      - uses: opentdf/otdfctl/e2e@main
        with:
          otdfctl-ref: "main"

  buflint:
    permissions:
      contents: read
    name: Protocol Buffer Lint and Gencode Up-to-date check
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          persist-credentials: false
      - uses: bufbuild/buf-setup-action@a47c93e0b1648d5651a065437926377d060baa99
        with:
          github_token: ${{ github.token }}
      - uses: bufbuild/buf-lint-action@06f9dd823d873146471cfaaf108a993fe00e5325
        with:
          input: service
      - uses: bufbuild/buf-breaking-action@c57b3d842a5c3f3b454756ef65305a50a587c5ba
        with:
          input: service
          against: "https://github.com/opentdf/platform.git#branch=main,subdir=service"
      - uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b #v5.4.0
        with:
          go-version-file: "service/go.mod"
          check-latest: false
          cache-dependency-path: |
            service/go.sum
            protocol/go/go.sum
            sdk/go.sum
            examples/go.sum
      - run: cd service && go get github.com/pseudomuto/protoc-gen-doc/cmd/protoc-gen-doc
      - run: cd service && go install github.com/pseudomuto/protoc-gen-doc/cmd/protoc-gen-doc
      - run: make proto-generate
      - name: Restore go.mod after installing protoc-gen-doc
        run: git restore {service,protocol/go}/go.{mod,sum}
      - name: validate go mod tidy
        run: |-
          cd protocol/go
          go mod tidy
          git restore go.sum
      - run: git diff
      - run: git diff-files --ignore-submodules
      - name: Check that make proto-generate has run before PR submission; see above for error details
        run: git diff-files --quiet --ignore-submodules

  ci:
    permissions: {}
    needs:
      - buflint
      - go
      - image
      - integration
      - benchmark
      - license
      - platform-xtest
      - otdfctl-test
    runs-on: ubuntu-22.04
    if: ${{ !cancelled() }} # Changed from needs.*.result check
    steps:
      # The individual job status (including benchmark failure) determines overall success/failure
      - name: Check Job Outcomes
        run: echo "CI check complete. Review individual job statuses."
      # No explicit failure check needed here anymore if benchmark job fails correctly

  license:
    permissions:
      contents: read
    name: license check
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.4.2
        with:
          persist-credentials: false
      - uses: actions/setup-go@0aaccfd150d50ccaeb58ebd88d36e91967a5f35b #v5.4.0
        with:
          go-version-file: "service/go.mod"
          check-latest: false
          cache: false
      - name: check service licenses
        run: >
          "$(go env GOROOT)"/bin/go run github.com/google/go-licenses@5348b744d0983d85713295ea08a20cca1654a45e
          check --disallowed_types=forbidden --include_tests
          ./service
      - name: check sdk licenses
        run: >
          "$(go env GOROOT)"/bin/go run github.com/google/go-licenses@5348b744d0983d85713295ea08a20cca1654a45e
          check --disallowed_types=forbidden --include_tests
          ./sdk
      - name: check examples licenses
        run: >
          "$(go env GOROOT)"/bin/go run github.com/google/go-licenses@5348b744d0983d85713295ea08a20cca1654a45e
          check --disallowed_types=forbidden --include_tests
          ./examples
